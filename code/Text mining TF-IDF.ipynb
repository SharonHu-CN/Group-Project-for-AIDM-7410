{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dd02837",
   "metadata": {},
   "source": [
    "## Text mining and TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d95722f",
   "metadata": {},
   "source": [
    "#### import functions and dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cc85f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e60f77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "jieba.load_userdict('dict.txt') \n",
    "stopwords = open('../data/停用词表.txt', 'r', encoding = 'utf8').readlines()\n",
    "stopwords = [w.strip() for w in stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ceabe6",
   "metadata": {},
   "source": [
    "#### Word segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c153b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For word segmentation\n",
    "tr = []\n",
    "\n",
    "fr = open('../data/2012.txt','r',encoding='utf-8')\n",
    "for w in fr.readlines():\n",
    "    w = w.strip()      \n",
    "    w = \"\".join(w.split())\n",
    "    if not len(w):                    \n",
    "        continue\n",
    "        \n",
    "    outstr = ''                          \n",
    "    \n",
    "    w = re.sub(r'[A-Za-z0-9]|/d+','',str(w)) \n",
    "    \n",
    "    seg_list = jieba.lcut(w, cut_all=False)   \n",
    "    for word in seg_list:\n",
    "        if word not in stopwords:            \n",
    "            if word != '\\t':                 \n",
    "                outstr += word\n",
    "                outstr += \" \"\n",
    "            \n",
    "    tr.append(outstr.strip().split(\" \"))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20fea00",
   "metadata": {},
   "source": [
    "#### the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a077c27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the results\n",
    "with open('2012.txt','w',encoding = 'utf-8') as file:\n",
    "    file.write(str(tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbec527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use jieba to do TF-IDF analysis\n",
    "from jieba import analyse\n",
    "tfidf = analyse.extract_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c90236",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('2012.txt','r',encoding='utf-8') as file:\n",
    "    texts = file.readlines()\n",
    "keywords = jieba.analyse.extract_tags(str(texts), topK=50, withWeight=True, allowPOS=('nr','ns','nt','nz','n','vn','v'))\n",
    "print(keywords)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e20c515",
   "metadata": {},
   "source": [
    "#### create dataframe and csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e61d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(keywords)\n",
    "output = df.to_csv('../output/topic_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2f213b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
